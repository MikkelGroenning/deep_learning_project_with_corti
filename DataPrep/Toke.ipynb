{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Interim/hydrated_Tweet200316.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "377045    False\n",
       "377046    False\n",
       "377047    False\n",
       "377048    False\n",
       "377049    False\n",
       "Length: 487972, dtype: bool"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         Large-scale testing for Covid-19 and wide avai...\n",
       "1                                   Stories on covid_19 üò±üò±üò±\n",
       "2         Smart. More of this, please. https://t.co/c7Tk...\n",
       "3         Not going to wear a bra for a month. üôÖüèª‚Äç‚ôÄÔ∏è‚ú®\\n\\...\n",
       "4         A COVID-19 coronavirus update from concerned p...\n",
       "                                ...                        \n",
       "377045    @charliekirk11 Democrats are using Covid19 to ...\n",
       "377046    Can‚Äôt wait to be an old woman telling my grand...\n",
       "377047    Y‚Äôall hate us sag so bad because we‚Äôre baddies...\n",
       "377048    I‚Äôm scared we‚Äôre going to be unwilling or unab...\n",
       "377049    @onhellmusic You didn't send me that mass text...\n",
       "Name: tweet, Length: 487972, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = make_multilabel_classification(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=0)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.83264691, 0.15610504, 0.00372766, 0.00372946, 0.00379093],\n",
       "       [0.11204968, 0.00563061, 0.00567138, 0.57851629, 0.29813204],\n",
       "       [0.00361638, 0.15391126, 0.31659894, 0.52227005, 0.00360337]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "lda.transform(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'asdnjsadnk'"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "re.sub('\\\\u20aa', '', 'asdnjsadnk\\u20aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tweets\n",
    "df['CleanTweet'] = [re.sub(\"[^a-zA-Z0-9\\s,.-_¬¥&%'\\\":‚Ç¨$¬£!?']\", '',  re.sub(' http\\S+', '', re.sub('\\s',' ', tw))).replace(u'\\xa0', u' ').lower() if isinstance(tw, str) else '' for tw in df.tweet]\n",
    "\n",
    "# Get bigrams\n",
    "bigrams_tweets = [list(nltk.bigrams(tw)) for tw in df['CleanTweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(''.join(set(''.join(df['CleanTweet'])))) # Assume all characters are in tweets from df1\n",
    "\n",
    "unique_bigrams = [x+y for x in unique_chars for y in unique_chars]\n",
    "\n",
    "bigram_mapper = dict(zip(unique_bigrams, range(len(unique_bigrams))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary = bigram_mapper, ngram_range = (2,2), analyzer = \"char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['CleanTweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(487972, 3481)"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 1 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 2 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 3 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 4 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 5 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 6 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 7 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 8 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 9 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 10 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, n_jobs=3, verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, verbose = 2, n_jobs = 3)\n",
    "lda.fit(X[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "topics = lda.transform(X[:10000]).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 424, 1: 891, 2: 4264, 3: 2179, 4: 2242}"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "y = np.bincount(topics)\n",
    "ii = np.nonzero(y)[0]\n",
    "dict(zip(ii,y[ii]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.16133972, 0.13859811, 0.69638492, 0.00183662, 0.00184063],\n",
       "       [0.58946017, 0.01020377, 0.01020963, 0.01012878, 0.37999766],\n",
       "       [0.00727604, 0.0072855 , 0.97082498, 0.00733381, 0.00727967],\n",
       "       ...,\n",
       "       [0.04489188, 0.00181722, 0.34178056, 0.39818723, 0.21332312],\n",
       "       [0.12547465, 0.37938139, 0.12883567, 0.00448361, 0.36182468],\n",
       "       [0.00400016, 0.11669848, 0.00396122, 0.18567844, 0.6896617 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "lda.transform(X[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-4636467.336107308"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ],
   "source": [
    "lda.score(X[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerTfidf = TfidfVectorizer(vocabulary = bigram_mapper, ngram_range = (2,2), analyzer = \"char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizerTfidf.fit_transform(df['CleanTweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 1 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 2 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 3 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 4 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 5 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 6 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 7 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 8 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 9 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "iteration: 10 of max_iter: 10\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, n_jobs=3, verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, verbose = 2, n_jobs = 3)\n",
    "lda.fit(X[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   3 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-455997.85389304534"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "source": [
    "lda.score(X[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<5x3481 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 233 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}