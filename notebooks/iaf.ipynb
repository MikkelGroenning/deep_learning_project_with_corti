{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from math import pi, log\n",
    "import torch \n",
    "from torch.nn import LSTM, Linear, Module\n",
    "from src.data.words import TwitterDataWords\n",
    "from src.models.iaf_words import *\n",
    "from src.data.common import get_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('../data/processed/200316_embedding.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitterwords = TwitterDataWords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = get_loader(twitterwords, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0014, -0.0141, -0.0194,  ...,  0.1428,  0.0714, -0.0579],\n",
       "        [-0.0314,  0.0149, -0.0205,  ...,  0.0980,  0.0893,  0.0148],\n",
       "        [ 0.0468, -0.0502,  0.0332,  ...,  0.1337,  0.0135, -0.0098],\n",
       "        ...,\n",
       "        [-0.0206,  0.0155, -0.0024,  ...,  0.0089, -0.0294, -0.0505],\n",
       "        [ 0.0460,  0.0312, -0.1643,  ...,  0.2473, -0.0198, -0.0882],\n",
       "        [ 0.2235,  0.0042,  0.0651,  ...,  0.1076,  0.1302, -0.0335]]), batch_sizes=tensor([10, 10, 10, 10, 10, 10, 10, 10, 10,  9,  9,  8,  7,  6,  5,  5,  5,  5,\n",
       "         5,  5,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  2,  1,  1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()\n",
    "ar_nn = AutoRegressiveNN(\n",
    "    input_dim=64+h_dim, \n",
    "    output_dim = 2*64,\n",
    "    layer1_dim = 200,\n",
    "    layer2_dim = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, log_sigma, h = enc(x)\n",
    "eps = torch.empty_like(mu).normal_()\n",
    "z = log_sigma.exp() * eps + mu \n",
    "l = -torch.sum(log_sigma + 1/2 * torch.pow(eps,2) + 1/2 * log(2*pi))\n",
    "T = 3\n",
    "for t in range(T):\n",
    "    m, s = ar_nn(z, h)\n",
    "    sigma = s.sigmoid()\n",
    "    z = sigma * z + (1 - sigma) * m\n",
    "    l = l - sigma.log().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IAF(Module):\n",
    "    def __init__(self, T, input_dim, output_dim, layer1_dim, layer2_dim):\n",
    "        \n",
    "        super(IAF, self).__init__()\n",
    "        self.T = T,\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.layer1_dim = layer1_dim\n",
    "        self.layer2_dim = layer2_dim\n",
    "        \n",
    "        self.ar_nn = AutoRegressiveNN(\n",
    "            input_dim=self.input_dim, \n",
    "            output_dim=self.output_dim,\n",
    "            layer1_dim=self.layer1_dim,\n",
    "            layer2_dim=self.layer2_dim\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, mu, log_sigma, h):\n",
    "        eps = torch.empty_like(mu).normal_()\n",
    "        z = log_sigma.exp() * eps + mu \n",
    "        l = -torch.sum(log_sigma + 1/2 * torch.pow(eps,2) + 1/2 * log(2*pi))\n",
    "        T = 3\n",
    "        for t in range(T):\n",
    "            m, s = ar_nn(z, h)\n",
    "            sigma = s.sigmoid()\n",
    "            z = sigma * z + (1 - sigma) * m\n",
    "            l = l - sigma.log().sum()\n",
    "        \n",
    "        return z, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "iaf = IAF(\n",
    "    T = 3,\n",
    "    input_dim=64+h_dim, \n",
    "    output_dim = 2*64,\n",
    "    layer1_dim = 200,\n",
    "    layer2_dim = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, l = iaf(*enc(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit ('deep-learning-vlae': conda)",
   "language": "python",
   "name": "python36264bitdeeplearningvlaecondaeca0108a4db4465f8b96217c4e658d21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
