{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.data.data_loader import TwitterDataset, alphabet, get_loader\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence, pack_padded_sequence, pad_sequence, PackedSequence\n",
    "from torch.nn import LSTM, Embedding, Module, Linear, ReLU, Sequential\n",
    "from torch.utils.data import DataLoader, Sampler, RandomSampler, BatchSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "\n",
    "# Import from 7.2 EXE\n",
    "from torch.distributions import Distribution\n",
    "from torch import Tensor\n",
    "\n",
    "from src.models.common import cuda, EmbeddingPacked, get_variable, get_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "data = pd.read_pickle('../data/interim/hydrated/200316.pkl')\n",
    "        \n",
    "dataset_train = TwitterDataset(data.iloc[:1000, :].copy())\n",
    "dataset_validation = TwitterDataset(data.iloc[1500:2000, :].copy())\n",
    "\n",
    "num_classes = len(alphabet)\n",
    "\n",
    "train_loader = get_loader( dataset_train, batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        return self.mu + self.sigma * self.sample_epsilon()\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        return torch.distributions.normal.Normal(self.mu, self.sigma).log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder1(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=64):\n",
    "        super(Encoder1, self).__init__()\n",
    "\n",
    "        self.n_features = len(alphabet)\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = 2 * embedding_dim\n",
    "\n",
    "        self.embedding = EmbeddingPacked(\n",
    "            num_embeddings = num_classes,\n",
    "            embedding_dim = 10,\n",
    "        )\n",
    "\n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size=10,\n",
    "            hidden_size=self.hidden_dim,\n",
    "            num_layers=1,\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size=self.hidden_dim,\n",
    "            hidden_size=self.embedding_dim,\n",
    "            num_layers=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, (_, _) = self.rnn1(x)\n",
    "        x, (hidden_n, _) = self.rnn2(x)\n",
    "        return hidden_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=64, num_layers=2):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = EmbeddingPacked(\n",
    "            num_embeddings = num_classes,\n",
    "            embedding_dim = 10,\n",
    "        )\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=10,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x, (hidden_n, _) = self.rnn(x)\n",
    "\n",
    "        return hidden_n[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=64, max_length=290, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.input_dim = input_dim\n",
    "        self.n_features = len(alphabet)\n",
    "\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.input_dim,\n",
    "            hidden_size=self.input_dim,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(self.input_dim, self.n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.repeat(self.max_length, 1, 1)\n",
    "\n",
    "        x, (_, _) = self.rnn(x)\n",
    "\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentVariationalAutoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=64, max_length = 290):\n",
    "\n",
    "        super(RecurrentVariationalAutoencoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.encoder = Encoder(self.embedding_dim)\n",
    "        self.decoder = Decoder(self.embedding_dim, max_length)\n",
    "\n",
    "        self.hidden2mean = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        self.hidden2logv = nn.Linear(self.embedding_dim, self.embedding_dim)\n",
    "        # MIGHT be different\n",
    "        # https://github.com/timbmg/Sentence-VAE/blob/master/model.py\n",
    "        self.latent2hidden = nn.Linear(self.embedding_dim, self.embedding_dim) \n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"\n",
    "        :param mu: mean from the encoder's latent space\n",
    "        :param log_var: log variance from the encoder's latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5*log_var) # standard deviation\n",
    "        eps = torch.randn_like(std) # `randn_like` as we need the same size\n",
    "        sample = mu + (eps * std) # sampling as if coming from the input space\n",
    "        return sample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        # Reparameterize \n",
    "        mu = self.hidden2mean(x)\n",
    "        log_var = self.hidden2logv(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "\n",
    "        # DECODER\n",
    "        hidden = self.latent2hidden(z)\n",
    "        x = self.decoder(hidden)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10/10 [00:32<00:00,  3.24s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.11s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.16s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.19s/it]\n",
      "100%|██████████| 10/10 [00:31<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize a new network\n",
    "rvae = RecurrentVariationalAutoencoder()\n",
    "\n",
    "# Hyper-parameters\n",
    "num_epochs = 10\n",
    "\n",
    "# Define a loss function and optimizer for this problem\n",
    "# YOUR CODE HERE!\n",
    "criterion = CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = SGD(rvae.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Track loss\n",
    "training_loss, validation_loss = [], []\n",
    "\n",
    "# For each epoch\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    # Track loss\n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "    rvae.train()\n",
    "    \n",
    "    # For each sentence in training set\n",
    "    for x in tqdm(train_loader):\n",
    "        \n",
    "        \n",
    "        x = get_variable(x)\n",
    "        \n",
    "        # Forward pass\n",
    "        # YOUR CODE HERE!\n",
    "        output = rvae(x)\n",
    "        \n",
    "        # Compute loss\n",
    "        # YOUR CODE HERE!\n",
    "        loss = criterion(\n",
    "            output.view(-1, 57),\n",
    "            pad_packed_sequence(x, total_length=290, padding_value=-1)[0].view(-1)\n",
    "        )\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_training_loss += loss.detach().numpy()\n",
    "        \n",
    "    # Save loss for plot\n",
    "    training_loss.append(epoch_training_loss/len(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.04028180646896362,\n",
       " 0.040242916107177736,\n",
       " 0.04018809986114502,\n",
       " 0.04013356351852417,\n",
       " 0.040068434238433835,\n",
       " 0.04000666093826294,\n",
       " 0.039949734687805175,\n",
       " 0.039885089159011844,\n",
       " 0.039826437473297116,\n",
       " 0.039759542942047116]"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_loader(TwitterDataset(data.iloc[5000:5005]), batch_size=5)\n",
    "x = next(iter(test_loader))\n",
    "results = rvae(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                                                                                                                                                                                                                                                                  \n                                                                                                                                                                                                                                                                                                  \n                                                                                                                                                                                                                                                                                                  \n                                                                                                                                                                                                                                                                                                  \n                                                                                                                                                                                                                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"\".join([alphabet[i] for i in results.argmax(axis=2)[:,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789,._´&’%\\'\":€$£!?#USE @'"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([300, 100])"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "pad_packed_sequence(x, total_length=300, padding_value=-1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([300, 100, 57])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[53, 53, 53,  ..., 53, 53, 53],\n",
       "         [51,  8,  7,  ...,  8,  2, 24],\n",
       "         [18, 55,  0,  ..., 55, 14,  4],\n",
       "         ...,\n",
       "         [-1, -1, -1,  ..., -1, -1, -1],\n",
       "         [-1, -1, -1,  ..., -1, -1, -1],\n",
       "         [-1, -1, -1,  ..., -1, -1, -1]]),\n",
       " tensor([272, 271, 271, 268, 261, 257, 252, 235, 233, 231, 228, 226, 225, 199,\n",
       "         199, 197, 197, 196, 183, 178, 175, 173, 171, 169, 167, 166, 165, 164,\n",
       "         162, 162, 154, 152, 151, 140, 126, 119, 117, 116, 116, 113, 112, 112,\n",
       "         101, 100,  98,  98,  95,  91,  87,  85,  84,  84,  83,  82,  81,  80,\n",
       "          79,  76,  75,  74,  72,  72,  72,  71,  70,  68,  65,  65,  64,  63,\n",
       "          62,  61,  60,  59,  59,  59,  57,  56,  55,  54,  49,  48,  45,  43,\n",
       "          43,  37,  37,  35,  34,  34,  27,  27,  26,  24,  22,  19,  14,  11,\n",
       "           9,   6]))"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "pad_packed_sequence(x, total_length=300, padding_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[53, 53, 53,  ..., 53, 53, 53],\n",
       "         [ 8,  8, 19,  ...,  0, 22,  8],\n",
       "         [55, 19,  7,  ..., 12,  4,  5],\n",
       "         ...,\n",
       "         [-1, -1, -1,  ..., -1, -1, -1],\n",
       "         [-1, -1, -1,  ..., -1, -1, -1],\n",
       "         [-1, -1, -1,  ..., -1, -1, -1]]),\n",
       " tensor([281, 279, 278, 277, 277, 277, 269, 264, 256, 256, 254, 249, 246, 243,\n",
       "         240, 239, 233, 230, 224, 213, 207, 206, 197, 192, 185, 177, 175, 167,\n",
       "         166, 163, 161, 160, 157, 156, 150, 150, 133, 131, 127, 126, 123, 117,\n",
       "         117, 107, 105, 103, 102, 101, 100, 100,  97,  95,  91,  88,  81,  79,\n",
       "          79,  79,  79,  77,  75,  73,  73,  72,  70,  69,  68,  64,  57,  54,\n",
       "          54,  54,  53,  52,  50,  46,  41,  39,  38,  37,  36,  35,  34,  34,\n",
       "          34,  33,  31,  30,  29,  27,  27,  25,  25,  21,  21,  21,  18,  18,\n",
       "          17,  16]))"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "pad_packed_sequence(x, total_length=300, padding_value=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/deep-learning-vlae/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d73276c40580c1b791c77282cdf03a43473a7aa7e67de6009dcfaf9e747a87f6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}